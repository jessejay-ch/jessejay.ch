# Robots.txt file for jessejay.ch
# This file is used to manage access for web crawlers and bots.

# Allow all web crawlers full access by default
User-agent: *
Disallow:

# Block access to sensitive directories
Disallow: /admin/
Disallow: /config/
Disallow: /private/
Disallow: /tmp/

# Block specific file types (if applicable)
Disallow: /*.sql$
Disallow: /*.log$
Disallow: /*.bak$

# Block access to script files
Disallow: /*.php$
Disallow: /*.js$

# Allow access to all other content
Allow: /

# Sitemap location
Sitemap: https://jessejay.ch/sitemap.xml
